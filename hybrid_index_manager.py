"""
Hybrid Search System - Index Manager Module

ã“ã®ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã¯ã€ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰æ¤œç´¢ã‚·ã‚¹ãƒ†ãƒ ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ç®¡ç†ã‚’æ‹…å½“ã—ã¾ã™ã€‚
BM25ã¨ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢ã®ä¸¡æ–¹ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’ç®¡ç†ã—ã€ãƒ•ã‚¡ã‚¤ãƒ«ç›£è¦–ã«ã‚ˆã‚‹è‡ªå‹•æ›´æ–°ã‚’æä¾›ã—ã¾ã™ã€‚
"""

import threading
import time
from pathlib import Path
from typing import Dict, Set, Optional
import concurrent.futures
import sys

# å¤–éƒ¨ãƒ©ã‚¤ãƒ–ãƒ©ãƒª
from watchdog.observers import Observer
from watchdog.events import FileSystemEventHandler

# å†…éƒ¨ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«
from core.base_system import HybridBaseSystem
from core.document_processor import DocumentProcessor
from retrievers.base_retriever import BaseRetriever
from retrievers.bm25_retriever import BM25Retriever
from retrievers.vector_retriever import VectorRetriever
import core.hybrid_config as config


class HybridIndexManager(HybridBaseSystem):
    """
    ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰æ¤œç´¢ã‚·ã‚¹ãƒ†ãƒ ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ç®¡ç†ã‚¯ãƒ©ã‚¹
    
    ã“ã®ã‚¯ãƒ©ã‚¹ã¯ä»¥ä¸‹ã®æ©Ÿèƒ½ã‚’æä¾›ã—ã¾ã™ï¼š
    - BM25ã¨ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢ã®ä¸¡æ–¹ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ç®¡ç†
    - ãƒ•ã‚¡ã‚¤ãƒ«ç›£è¦–ã«ã‚ˆã‚‹è‡ªå‹•ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹æ›´æ–°
    - ä¸¦åˆ—å‡¦ç†ã«ã‚ˆã‚‹åŠ¹ç‡çš„ãªå‡¦ç†
    - çµ±åˆã•ã‚ŒãŸãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆå‡¦ç†
    """
    
    def __init__(self):
        """
        HybridIndexManagerã‚’åˆæœŸåŒ–ã—ã¾ã™ã€‚
        """
        super().__init__()
        self.logger.info("HybridIndexManageråˆæœŸåŒ–ã‚’é–‹å§‹ã—ã¾ã™")
        
        # ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆå‡¦ç†ã‚·ã‚¹ãƒ†ãƒ 
        self.document_processor = DocumentProcessor()
        
        # æ¤œç´¢ã‚¨ãƒ³ã‚¸ãƒ³ã®åˆæœŸåŒ–
        self.retrievers: Dict[str, BaseRetriever] = {}
        self._initialize_retrievers()
        
        # ãƒ•ã‚¡ã‚¤ãƒ«ç›£è¦–ã‚·ã‚¹ãƒ†ãƒ 
        self.observer: Optional[Observer] = None
        self.file_handler: Optional[FileChangeHandler] = None
        
        # å‡¦ç†ã‚­ãƒ¥ãƒ¼ã¨ãƒ¯ãƒ¼ã‚«ãƒ¼
        self.processing_queue: Set[Path] = set()  # å‡¦ç†å¾…ã¡ãƒ•ã‚¡ã‚¤ãƒ«
        self.processing_lock = threading.Lock()
        
        # è‡ªå‹•ä¿å­˜ã‚¿ã‚¤ãƒãƒ¼
        self.autosave_timer: Optional[threading.Timer] = None
        
        # çµ±è¨ˆæƒ…å ±
        self.stats = {
            'files_processed': 0,
            'files_added': 0,
            'files_updated': 0,
            'files_removed': 0,
            'last_update': None
        }
        
        # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹æ›´æ–°é€šçŸ¥ã‚·ã‚¹ãƒ†ãƒ 
        self.update_notifier = None
        
        self.logger.info("HybridIndexManageråˆæœŸåŒ–å®Œäº†")
    
    def _initialize_retrievers(self) -> None:
        """
        æ¤œç´¢ã‚¨ãƒ³ã‚¸ãƒ³ã‚’åˆæœŸåŒ–ã—ã¾ã™ã€‚
        """
        try:
            # BM25æ¤œç´¢ã‚¨ãƒ³ã‚¸ãƒ³
            self.logger.info("BM25æ¤œç´¢ã‚¨ãƒ³ã‚¸ãƒ³ã‚’åˆæœŸåŒ–ä¸­...")
            bm25_retriever = BM25Retriever()
            if bm25_retriever.initialize():
                self.retrievers['bm25'] = bm25_retriever
                self.logger.info("BM25æ¤œç´¢ã‚¨ãƒ³ã‚¸ãƒ³ã®åˆæœŸåŒ–å®Œäº†")
            else:
                self.logger.error("BM25æ¤œç´¢ã‚¨ãƒ³ã‚¸ãƒ³ã®åˆæœŸåŒ–ã«å¤±æ•—")
            
            # ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢ã‚¨ãƒ³ã‚¸ãƒ³
            self.logger.info("ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢ã‚¨ãƒ³ã‚¸ãƒ³ã‚’åˆæœŸåŒ–ä¸­...")
            vector_retriever = VectorRetriever()
            if vector_retriever.initialize():
                self.retrievers['vector'] = vector_retriever
                self.logger.info("ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢ã‚¨ãƒ³ã‚¸ãƒ³ã®åˆæœŸåŒ–å®Œäº†")
            else:
                self.logger.error("ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢ã‚¨ãƒ³ã‚¸ãƒ³ã®åˆæœŸåŒ–ã«å¤±æ•—")
            
            self.logger.info(f"æ¤œç´¢ã‚¨ãƒ³ã‚¸ãƒ³åˆæœŸåŒ–å®Œäº†: {list(self.retrievers.keys())}")
            
        except Exception as e:
            self.logger.error(f"æ¤œç´¢ã‚¨ãƒ³ã‚¸ãƒ³åˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {e}")
            sys.exit(1)
    
    def initialize_indices(self) -> bool:
        """
        åˆæœŸã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’ä½œæˆã—ã¾ã™ã€‚
        
        Returns:
            bool: åˆæœŸåŒ–ã«æˆåŠŸã—ãŸå ´åˆTrue
        """
        self.logger.info("åˆæœŸã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ä½œæˆã‚’é–‹å§‹ã—ã¾ã™")
        
        try:
            # ç›£è¦–ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®å­˜åœ¨ç¢ºèª
            if not config.WATCH_DIRECTORY.exists():
                self.logger.error(f"ç›£è¦–ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒå­˜åœ¨ã—ã¾ã›ã‚“: {config.WATCH_DIRECTORY}")
                return False
            
            # åˆæœŸã‚¹ã‚­ãƒ£ãƒ³ãƒ¢ãƒ¼ãƒ‰ã®ç¢ºèª
            if config.INDEX_STARTUP_MODE == "skip":
                self.logger.info("åˆæœŸã‚¹ã‚­ãƒ£ãƒ³ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™")
                return True
            
            # ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¹ã‚­ãƒ£ãƒ³
            processed_docs = self.document_processor.process_directory(
                config.WATCH_DIRECTORY, 
                config.RECURSIVE_WATCH
            )
            
            if not processed_docs:
                self.logger.info("å‡¦ç†å¯¾è±¡ã®ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
                return True
            
            # çµ±è¨ˆæƒ…å ±ã‚’ãƒ­ã‚°å‡ºåŠ›
            self.document_processor.log_processing_stats(processed_docs)
            
            # å„æ¤œç´¢ã‚¨ãƒ³ã‚¸ãƒ³ã«ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’è¿½åŠ 
            self.logger.info(f"ğŸ“š åˆæœŸã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹æ§‹ç¯‰: {len(processed_docs)}ä»¶ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’è¿½åŠ ä¸­...")
            self._add_documents_to_all_retrievers(processed_docs)
            
            # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’å†æ§‹ç¯‰
            self.logger.info("ğŸ”§ ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹å†æ§‹ç¯‰ã‚’å®Ÿè¡Œä¸­...")
            self._rebuild_all_indices()
            
            # å„ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã®æœ€çµ‚çŠ¶æ…‹ã‚’ãƒ­ã‚°å‡ºåŠ›
            for name, retriever in self.retrievers.items():
                doc_count = retriever.get_document_count()
                self.logger.info(f"ğŸ“Š {name}ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹æœ€çµ‚çŠ¶æ…‹: {doc_count}ä»¶ã®æ–‡æ›¸")
            
            # çµ±è¨ˆæ›´æ–°
            self.stats['files_processed'] += len(processed_docs)
            self.stats['files_added'] += len(processed_docs)
            self.stats['last_update'] = time.time()
            
            self.logger.info(f"åˆæœŸã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ä½œæˆå®Œäº†: {len(processed_docs)}ä»¶å‡¦ç†")
            return True
            
        except Exception as e:
            self.logger.error(f"åˆæœŸã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ä½œæˆã‚¨ãƒ©ãƒ¼: {e}")
            return False
    
    def start_file_watching(self) -> bool:
        """
        ãƒ•ã‚¡ã‚¤ãƒ«ç›£è¦–ã‚’é–‹å§‹ã—ã¾ã™ã€‚
        
        Returns:
            bool: ç›£è¦–é–‹å§‹ã«æˆåŠŸã—ãŸå ´åˆTrue
        """
        try:
            self.file_handler = FileChangeHandler(self)
            self.observer = Observer()
            
            self.observer.schedule(
                self.file_handler,
                str(config.WATCH_DIRECTORY),
                recursive=config.RECURSIVE_WATCH
            )
            
            self.observer.start()
            self.logger.info(f"ãƒ•ã‚¡ã‚¤ãƒ«ç›£è¦–é–‹å§‹: {config.WATCH_DIRECTORY}")
            return True
            
        except Exception as e:
            self.logger.error(f"ãƒ•ã‚¡ã‚¤ãƒ«ç›£è¦–é–‹å§‹ã‚¨ãƒ©ãƒ¼: {e}")
            return False
    
    def stop_file_watching(self) -> None:
        """
        ãƒ•ã‚¡ã‚¤ãƒ«ç›£è¦–ã‚’åœæ­¢ã—ã¾ã™ã€‚
        """
        if self.observer and self.observer.is_alive():
            self.observer.stop()
            self.observer.join()
            self.logger.info("ãƒ•ã‚¡ã‚¤ãƒ«ç›£è¦–ã‚’åœæ­¢ã—ã¾ã—ãŸ")
    
    def start_auto_save(self) -> None:
        """
        è‡ªå‹•ä¿å­˜ã‚¿ã‚¤ãƒãƒ¼ã‚’é–‹å§‹ã—ã¾ã™ã€‚
        """
        if config.ENABLE_AUTOSAVE:
            self._schedule_auto_save()
            self.logger.info(f"è‡ªå‹•ä¿å­˜ã‚¿ã‚¤ãƒãƒ¼é–‹å§‹: {config.AUTOSAVE_INTERVAL}ç§’é–“éš”")
    
    def stop_auto_save(self) -> None:
        """
        è‡ªå‹•ä¿å­˜ã‚¿ã‚¤ãƒãƒ¼ã‚’åœæ­¢ã—ã¾ã™ã€‚
        """
        if self.autosave_timer:
            self.autosave_timer.cancel()
            self.autosave_timer = None
            self.logger.info("è‡ªå‹•ä¿å­˜ã‚¿ã‚¤ãƒãƒ¼ã‚’åœæ­¢ã—ã¾ã—ãŸ")
    
    def _schedule_auto_save(self) -> None:
        """
        æ¬¡å›ã®è‡ªå‹•ä¿å­˜ã‚’ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ã—ã¾ã™ã€‚
        """
        if config.ENABLE_AUTOSAVE:
            self.autosave_timer = threading.Timer(
                config.AUTOSAVE_INTERVAL, 
                self._execute_auto_save
            )
            self.autosave_timer.start()
    
    def _execute_auto_save(self) -> None:
        """
        è‡ªå‹•ä¿å­˜ã‚’å®Ÿè¡Œã—ã¾ã™ã€‚
        """
        self.logger.info("è‡ªå‹•ä¿å­˜ã‚’å®Ÿè¡Œã—ã¾ã™")
        self.save_all_indices()
        # æ¬¡å›ã®è‡ªå‹•ä¿å­˜ã‚’ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«
        self._schedule_auto_save()
    
    def save_all_indices(self) -> bool:
        """
        å…¨ã¦ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’ä¿å­˜ã—ã¾ã™ã€‚
        
        Returns:
            bool: ä¿å­˜ã«æˆåŠŸã—ãŸå ´åˆTrue
        """
        success = True
        
        for name, retriever in self.retrievers.items():
            try:
                if retriever.save_index():
                    self.logger.debug(f"{name}ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ä¿å­˜æˆåŠŸ")
                else:
                    self.logger.warning(f"{name}ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ä¿å­˜å¤±æ•—")
                    success = False
            except Exception as e:
                self.logger.error(f"{name}ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")
                success = False
        
        if success:
            self.logger.info("å…¨ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ä¿å­˜å®Œäº†")
        
        return success
    
    def add_or_update_file(self, file_path: Path) -> None:
        """
        ãƒ•ã‚¡ã‚¤ãƒ«ã‚’è¿½åŠ ã¾ãŸã¯æ›´æ–°ã—ã¾ã™ã€‚
        
        Args:
            file_path (Path): å‡¦ç†ã™ã‚‹ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
        """
        with self.processing_lock:
            # é‡è¤‡å‡¦ç†ã‚’é˜²ã
            if file_path in self.processing_queue:
                return
            self.processing_queue.add(file_path)
        
        self.logger.info(f"ğŸ“„ ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†é–‹å§‹: {file_path.name}")
        
        try:
            # ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‡¦ç†
            processed_doc = self.document_processor.process_file(file_path)
            
            if processed_doc:
                doc_id = processed_doc.doc_id
                self.logger.info(f"ğŸ“‹ ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆå‡¦ç†å®Œäº†: {doc_id}")
                
                # æ—¢å­˜ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®ãƒã‚§ãƒƒã‚¯ã¨å‰Šé™¤
                is_update = False
                for name, retriever in self.retrievers.items():
                    doc_count_before = retriever.get_document_count()
                    if doc_count_before > 0 and retriever.remove_document(doc_id):
                        doc_count_after = retriever.get_document_count()
                        self.logger.info(f"ğŸ—‘ï¸  {name}ã‹ã‚‰æ—¢å­˜æ–‡æ›¸å‰Šé™¤: {doc_id} (æ–‡æ›¸æ•°: {doc_count_before} â†’ {doc_count_after})")
                        is_update = True
                
                # å…¨ã¦ã®æ¤œç´¢ã‚¨ãƒ³ã‚¸ãƒ³ã«è¿½åŠ 
                success = self._add_document_to_all_retrievers(processed_doc)
                
                if success:
                    # çµ±è¨ˆæ›´æ–°
                    self.stats['files_processed'] += 1
                    if is_update:
                        self.stats['files_updated'] += 1
                        self.logger.info(f"âœ… ãƒ•ã‚¡ã‚¤ãƒ«æ›´æ–°å®Œäº†: {file_path.name}")
                    else:
                        self.stats['files_added'] += 1
                        self.logger.info(f"âœ… ãƒ•ã‚¡ã‚¤ãƒ«è¿½åŠ å®Œäº†: {file_path.name}")
                    self.stats['last_update'] = time.time()
                    
                    # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’ä¿å­˜ï¼ˆè‡ªå‹•ä¿å­˜ãŒæœ‰åŠ¹ãªå ´åˆï¼‰
                    if config.ENABLE_AUTOSAVE:
                        self.save_all_indices()
                    
                    # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹æ›´æ–°é€šçŸ¥ã‚’é€ä¿¡
                    for name in self.retrievers.keys():
                        self._notify_index_update(name)
                else:
                    self.logger.error(f"âŒ ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†å¤±æ•—: {file_path.name}")
            else:
                self.logger.warning(f"âš ï¸  ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†ã‚¹ã‚­ãƒƒãƒ—ï¼ˆéå¯¾å¿œå½¢å¼ï¼‰: {file_path.name}")
                
        except Exception as e:
            self.logger.error(f"âŒ ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†ã‚¨ãƒ©ãƒ¼ {file_path.name}: {e}")
        
        finally:
            # å‡¦ç†ã‚­ãƒ¥ãƒ¼ã‹ã‚‰å‰Šé™¤
            with self.processing_lock:
                self.processing_queue.discard(file_path)
    
    def remove_file(self, file_path: Path) -> None:
        """
        ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤ã—ã¾ã™ã€‚
        
        Args:
            file_path (Path): å‰Šé™¤ã™ã‚‹ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
        """
        self.logger.info(f"ğŸ—‘ï¸  ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤é–‹å§‹: {file_path.name}")
        
        try:
            doc_id = str(file_path)
            
            # å„æ¤œç´¢ã‚¨ãƒ³ã‚¸ãƒ³ã‹ã‚‰å‰Šé™¤
            removed_count = 0
            for name, retriever in self.retrievers.items():
                doc_count_before = retriever.get_document_count()
                if retriever.remove_document(doc_id):
                    doc_count_after = retriever.get_document_count()
                    self.logger.info(f"ğŸ—‘ï¸  {name}ã‹ã‚‰æ–‡æ›¸å‰Šé™¤æˆåŠŸ: {doc_id} (æ–‡æ›¸æ•°: {doc_count_before} â†’ {doc_count_after})")
                    removed_count += 1
                else:
                    self.logger.debug(f"ğŸ” {name}ã«å‰Šé™¤å¯¾è±¡æ–‡æ›¸ãªã—: {doc_id}")
            
            if removed_count > 0:
                self.stats['files_removed'] += 1
                self.stats['last_update'] = time.time()
                self.logger.info(f"âœ… ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤å®Œäº†: {file_path.name} ({removed_count}/{len(self.retrievers)}å€‹ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‹ã‚‰å‰Šé™¤)")
                
                # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’ä¿å­˜ï¼ˆè‡ªå‹•ä¿å­˜ãŒæœ‰åŠ¹ãªå ´åˆï¼‰
                if config.ENABLE_AUTOSAVE:
                    self.save_all_indices()
                
                # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹æ›´æ–°é€šçŸ¥ã‚’é€ä¿¡
                for name in self.retrievers.keys():
                    self._notify_index_update(name)
            else:
                self.logger.warning(f"âš ï¸  å‰Šé™¤å¯¾è±¡ãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã«è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {file_path.name}")
            
        except Exception as e:
            self.logger.error(f"âŒ ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤ã‚¨ãƒ©ãƒ¼ {file_path.name}: {e}")
    
    def _add_document_to_all_retrievers(self, processed_doc) -> bool:
        """
        ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’å…¨ã¦ã®æ¤œç´¢ã‚¨ãƒ³ã‚¸ãƒ³ã«è¿½åŠ ã—ã¾ã™ã€‚
        
        Args:
            processed_doc: å‡¦ç†æ¸ˆã¿ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ
            
        Returns:
            bool: å…¨ã¦æˆåŠŸã—ãŸå ´åˆTrue
        """
        success = True
        successful_additions = 0
        
        for name, retriever in self.retrievers.items():
            try:
                doc_count_before = retriever.get_document_count()
                if retriever.add_document(processed_doc):
                    doc_count_after = retriever.get_document_count()
                    self.logger.info(f"â• {name}ã¸ã®æ–‡æ›¸è¿½åŠ æˆåŠŸ: {processed_doc.file_path.name} (æ–‡æ›¸æ•°: {doc_count_before} â†’ {doc_count_after})")
                    successful_additions += 1
                else:
                    self.logger.warning(f"âš ï¸  {name}ã¸ã®æ–‡æ›¸è¿½åŠ å¤±æ•—: {processed_doc.file_path.name}")
                    success = False
            except Exception as e:
                self.logger.error(f"âŒ {name}ã¸ã®æ–‡æ›¸è¿½åŠ ã‚¨ãƒ©ãƒ¼: {processed_doc.file_path.name} - {e}")
                success = False
        
        if success:
            self.logger.info(f"âœ… å…¨ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã¸ã®è¿½åŠ å®Œäº†: {processed_doc.file_path.name} ({successful_additions}/{len(self.retrievers)}å€‹ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹)")
        else:
            self.logger.error(f"âŒ ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹è¿½åŠ ã§ä¸€éƒ¨å¤±æ•—: {processed_doc.file_path.name} ({successful_additions}/{len(self.retrievers)}å€‹æˆåŠŸ)")
        
        return success
    
    def _add_documents_to_all_retrievers(self, processed_docs) -> None:
        """
        è¤‡æ•°ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’å…¨ã¦ã®æ¤œç´¢ã‚¨ãƒ³ã‚¸ãƒ³ã«è¿½åŠ ã—ã¾ã™ï¼ˆä¸¦åˆ—å‡¦ç†ï¼‰ã€‚
        
        Args:
            processed_docs: å‡¦ç†æ¸ˆã¿ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®ãƒªã‚¹ãƒˆ
        """
        self.logger.info(f"ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆè¿½åŠ é–‹å§‹: {len(processed_docs)}ä»¶")
        
        # ä¸¦åˆ—å‡¦ç†ã§åŠ¹ç‡åŒ–
        with concurrent.futures.ThreadPoolExecutor(max_workers=config.MAX_WORKERS) as executor:
            futures = []
            
            for processed_doc in processed_docs:
                future = executor.submit(self._add_document_to_all_retrievers, processed_doc)
                futures.append(future)
            
            # å®Œäº†ã‚’å¾…æ©Ÿ
            completed = 0
            for future in concurrent.futures.as_completed(futures):
                completed += 1
                if completed % 10 == 0:
                    self.logger.info(f"ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆè¿½åŠ é€²æ—: {completed}/{len(processed_docs)}")
        
        self.logger.info("ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆè¿½åŠ å®Œäº†")
    
    def _rebuild_all_indices(self) -> None:
        """
        å…¨ã¦ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’å†æ§‹ç¯‰ã—ã¾ã™ã€‚
        """
        self.logger.info("å…¨ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹å†æ§‹ç¯‰ã‚’é–‹å§‹ã—ã¾ã™")
        
        for name, retriever in self.retrievers.items():
            try:
                if hasattr(retriever, 'rebuild_index'):
                    if retriever.rebuild_index():
                        self.logger.info(f"{name}ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹å†æ§‹ç¯‰å®Œäº†")
                    else:
                        self.logger.warning(f"{name}ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹å†æ§‹ç¯‰å¤±æ•—")
            except Exception as e:
                self.logger.error(f"{name}ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹å†æ§‹ç¯‰ã‚¨ãƒ©ãƒ¼: {e}")
        
        self.logger.info("å…¨ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹å†æ§‹ç¯‰å®Œäº†")
    
    def get_system_status(self) -> Dict:
        """
        ã‚·ã‚¹ãƒ†ãƒ çŠ¶æ…‹ã‚’å–å¾—ã—ã¾ã™ã€‚
        
        Returns:
            Dict: ã‚·ã‚¹ãƒ†ãƒ çŠ¶æ…‹æƒ…å ±
        """
        self.logger.info("ğŸ“ˆ ã‚·ã‚¹ãƒ†ãƒ çŠ¶æ…‹ãƒã‚§ãƒƒã‚¯å®Ÿè¡Œä¸­...")
        
        retriever_status = {}
        for name, retriever in self.retrievers.items():
            doc_count = retriever.get_document_count()
            is_ready = retriever.is_ready()
            
            retriever_status[name] = {
                'initialized': retriever.is_initialized,
                'ready': is_ready,
                'document_count': doc_count,
                'info': retriever.get_index_info()
            }
            
            # å„ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã®çŠ¶æ…‹ã‚’ãƒ­ã‚°å‡ºåŠ›
            status_icon = "âœ…" if is_ready else "âŒ"
            self.logger.info(f"ğŸ“Š {status_icon} {name}ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹: {doc_count}ä»¶ã®æ–‡æ›¸, {'æº–å‚™å®Œäº†' if is_ready else 'æœªæº–å‚™'}")
        
        status = {
            'is_watching': self.observer is not None and self.observer.is_alive(),
            'auto_save_enabled': config.ENABLE_AUTOSAVE,
            'processing_queue_size': len(self.processing_queue),
            'retrievers': retriever_status,
            'statistics': self.stats.copy(),
            'config_summary': {
                'watch_directory': str(config.WATCH_DIRECTORY),
                'supported_extensions': list(config.SUPPORTED_EXTENSIONS),
                'recursive_watch': config.RECURSIVE_WATCH,
                'max_workers': config.MAX_WORKERS
            }
        }
        
        # çµ±è¨ˆæƒ…å ±ã‚‚ãƒ­ã‚°å‡ºåŠ›
        self.logger.info(f"ğŸ“Š å‡¦ç†çµ±è¨ˆ: å‡¦ç†{self.stats['files_processed']}ä»¶, è¿½åŠ {self.stats['files_added']}ä»¶, æ›´æ–°{self.stats['files_updated']}ä»¶, å‰Šé™¤{self.stats['files_removed']}ä»¶")
        
        return status
    
    def get_retriever(self, name: str) -> Optional[BaseRetriever]:
        """
        æŒ‡å®šã—ãŸåå‰ã®æ¤œç´¢ã‚¨ãƒ³ã‚¸ãƒ³ã‚’å–å¾—ã—ã¾ã™ã€‚
        
        Args:
            name (str): æ¤œç´¢ã‚¨ãƒ³ã‚¸ãƒ³åï¼ˆ"bm25" or "vector"ï¼‰
            
        Returns:
            Optional[BaseRetriever]: æ¤œç´¢ã‚¨ãƒ³ã‚¸ãƒ³ã€‚è¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã¯None
        """
        return self.retrievers.get(name)
    
    def set_update_notifier(self, notifier) -> None:
        """
        ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹æ›´æ–°é€šçŸ¥ã‚·ã‚¹ãƒ†ãƒ ã‚’è¨­å®šã—ã¾ã™ã€‚
        
        Args:
            notifier: æ›´æ–°é€šçŸ¥ã‚·ã‚¹ãƒ†ãƒ 
        """
        self.update_notifier = notifier
        self.logger.info("ğŸ”” ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹æ›´æ–°é€šçŸ¥ã‚·ã‚¹ãƒ†ãƒ ã‚’è¨­å®šã—ã¾ã—ãŸ")
    
    def _notify_index_update(self, retriever_name: str) -> None:
        """
        ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹æ›´æ–°ã‚’é€šçŸ¥ã—ã¾ã™ã€‚
        
        Args:
            retriever_name (str): æ›´æ–°ã•ã‚ŒãŸãƒªãƒˆãƒªãƒ¼ãƒãƒ¼å
        """
        if self.update_notifier:
            try:
                self.update_notifier.notify_update(retriever_name)
                self.logger.debug(f"ğŸ“£ ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹æ›´æ–°é€šçŸ¥é€ä¿¡: {retriever_name}")
            except Exception as e:
                self.logger.error(f"ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹æ›´æ–°é€šçŸ¥ã‚¨ãƒ©ãƒ¼: {e}")


class FileChangeHandler(FileSystemEventHandler):
    """
    ãƒ•ã‚¡ã‚¤ãƒ«ã‚·ã‚¹ãƒ†ãƒ å¤‰æ›´ã‚’å‡¦ç†ã™ã‚‹ãƒãƒ³ãƒ‰ãƒ©ãƒ¼
    """
    
    def __init__(self, index_manager: HybridIndexManager):
        """
        ãƒãƒ³ãƒ‰ãƒ©ãƒ¼ã‚’åˆæœŸåŒ–ã—ã¾ã™ã€‚
        
        Args:
            index_manager (HybridIndexManager): ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ç®¡ç†ã‚·ã‚¹ãƒ†ãƒ 
        """
        self.index_manager = index_manager
        self.logger = index_manager.logger
        
        # å¤‰æ›´å‡¦ç†ã®é…å»¶å®Ÿè¡Œç”¨
        self.pending_changes = {}  # {path: timer}
        self.change_lock = threading.Lock()
    
    def on_created(self, event):
        """ãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆã‚¤ãƒ™ãƒ³ãƒˆ"""
        if not event.is_directory:
            self.logger.info(f"ãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆã‚¤ãƒ™ãƒ³ãƒˆ: {event.src_path}")
            self._schedule_file_change(Path(event.src_path))
    
    def on_modified(self, event):
        """ãƒ•ã‚¡ã‚¤ãƒ«å¤‰æ›´ã‚¤ãƒ™ãƒ³ãƒˆ"""
        if not event.is_directory:
            self.logger.info(f"ãƒ•ã‚¡ã‚¤ãƒ«å¤‰æ›´ã‚¤ãƒ™ãƒ³ãƒˆ: {event.src_path}")
            self._schedule_file_change(Path(event.src_path))
    
    def on_deleted(self, event):
        """ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤ã‚¤ãƒ™ãƒ³ãƒˆ"""
        if not event.is_directory:
            self.logger.info(f"ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤ã‚¤ãƒ™ãƒ³ãƒˆ: {event.src_path}")
            file_path = Path(event.src_path)
            
            # ä¿ç•™ä¸­ã®å¤‰æ›´ã‚’ã‚­ãƒ£ãƒ³ã‚»ãƒ«
            self._cancel_pending_change(file_path)
            
            # å‰Šé™¤å‡¦ç†
            timer = threading.Timer(
                config.REBUILD_DELAY,
                self.index_manager.remove_file,
                args=[file_path]
            )
            timer.start()
    
    def _schedule_file_change(self, file_path: Path) -> None:
        """
        ãƒ•ã‚¡ã‚¤ãƒ«å¤‰æ›´å‡¦ç†ã‚’ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ã—ã¾ã™ï¼ˆé€£ç¶šå¤‰æ›´ã¸ã®å¯¾å¿œï¼‰ã€‚
        
        Args:
            file_path (Path): å¤‰æ›´ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«
        """
        with self.change_lock:
            # æ—¢å­˜ã®ä¿ç•™ä¸­å‡¦ç†ã‚’ã‚­ãƒ£ãƒ³ã‚»ãƒ«
            self._cancel_pending_change(file_path)
            
            # æ–°ã—ã„å‡¦ç†ã‚’ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«
            timer = threading.Timer(
                config.REBUILD_DELAY,
                self._process_file_change,
                args=[file_path]
            )
            timer.start()
            self.pending_changes[file_path] = timer
    
    def _cancel_pending_change(self, file_path: Path) -> None:
        """
        ä¿ç•™ä¸­ã®å¤‰æ›´å‡¦ç†ã‚’ã‚­ãƒ£ãƒ³ã‚»ãƒ«ã—ã¾ã™ã€‚
        
        Args:
            file_path (Path): å¯¾è±¡ãƒ•ã‚¡ã‚¤ãƒ«
        """
        if file_path in self.pending_changes:
            self.pending_changes[file_path].cancel()
            del self.pending_changes[file_path]
    
    def _process_file_change(self, file_path: Path) -> None:
        """
        ãƒ•ã‚¡ã‚¤ãƒ«å¤‰æ›´ã‚’å‡¦ç†ã—ã¾ã™ã€‚
        
        Args:
            file_path (Path): å¤‰æ›´ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«
        """
        self.logger.info(f"ğŸ”„ ãƒ•ã‚¡ã‚¤ãƒ«å¤‰æ›´å‡¦ç†é–‹å§‹: {file_path.name}")
        
        try:
            # ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ã€ã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
            if file_path.exists():
                if self.index_manager.document_processor.is_supported_file(file_path):
                    self.logger.info(f"ğŸ“‚ ã‚µãƒãƒ¼ãƒˆå½¢å¼ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‡¦ç†: {file_path.name}")
                    self.index_manager.add_or_update_file(file_path)
                else:
                    self.logger.debug(f"ğŸš« éã‚µãƒãƒ¼ãƒˆå½¢å¼ã®ãƒ•ã‚¡ã‚¤ãƒ«: {file_path.name}")
            else:
                self.logger.warning(f"â“ ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ã¾ã›ã‚“: {file_path.name}")
        
        except Exception as e:
            self.logger.error(f"âŒ ãƒ•ã‚¡ã‚¤ãƒ«å¤‰æ›´å‡¦ç†ã‚¨ãƒ©ãƒ¼ {file_path.name}: {e}")
        
        finally:
            # ä¿ç•™ãƒªã‚¹ãƒˆã‹ã‚‰å‰Šé™¤
            with self.change_lock:
                self.pending_changes.pop(file_path, None)
            self.logger.debug(f"ğŸ ãƒ•ã‚¡ã‚¤ãƒ«å¤‰æ›´å‡¦ç†çµ‚äº†: {file_path.name}")


def main():
    """
    ãƒ¡ã‚¤ãƒ³é–¢æ•°ï¼šãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼ã‚’å®Ÿè¡Œã—ã¾ã™ã€‚
    """
    print("=== Hybrid Search System - Index Manager ===")
    print(config.get_config_summary())
    
    # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼ã®åˆæœŸåŒ–
    index_manager = HybridIndexManager()
    
    try:
        # åˆæœŸã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ä½œæˆ
        if not index_manager.initialize_indices():
            print("åˆæœŸã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ä½œæˆã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
            sys.exit(1)
        
        # ãƒ•ã‚¡ã‚¤ãƒ«ç›£è¦–é–‹å§‹
        if not index_manager.start_file_watching():
            print("ãƒ•ã‚¡ã‚¤ãƒ«ç›£è¦–ã®é–‹å§‹ã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
            sys.exit(1)
        
        # è‡ªå‹•ä¿å­˜é–‹å§‹
        index_manager.start_auto_save()
        
        print("\nãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ç®¡ç†ã‚·ã‚¹ãƒ†ãƒ ãŒé–‹å§‹ã•ã‚Œã¾ã—ãŸã€‚")
        print("ãƒ•ã‚¡ã‚¤ãƒ«ç›£è¦–ã¨ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹æ›´æ–°ã‚’å®Ÿè¡Œä¸­...")
        print("ã‚·ã‚¹ãƒ†ãƒ çŠ¶æ…‹ç¢ºèª: Ctrl+S")
        print("çµ‚äº†: Ctrl+C")
        
        # ãƒ¡ã‚¤ãƒ³ãƒ«ãƒ¼ãƒ—
        while True:
            try:
                time.sleep(1)
            except KeyboardInterrupt:
                break
    
    except KeyboardInterrupt:
        pass
    
    finally:
        print("\n\nãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ç®¡ç†ã‚·ã‚¹ãƒ†ãƒ ã‚’çµ‚äº†ä¸­...")
        
        # ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
        index_manager.stop_file_watching()
        index_manager.stop_auto_save()
        index_manager.save_all_indices()
        
        # æœ€çµ‚çŠ¶æ…‹è¡¨ç¤º
        status = index_manager.get_system_status()
        print(f"æœ€çµ‚å‡¦ç†çµ±è¨ˆ:")
        print(f"  å‡¦ç†ãƒ•ã‚¡ã‚¤ãƒ«æ•°: {status['statistics']['files_processed']}")
        print(f"  è¿½åŠ : {status['statistics']['files_added']}")
        print(f"  æ›´æ–°: {status['statistics']['files_updated']}")
        print(f"  å‰Šé™¤: {status['statistics']['files_removed']}")
        
        print("ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ç®¡ç†ã‚·ã‚¹ãƒ†ãƒ ã‚’æ­£å¸¸çµ‚äº†ã—ã¾ã—ãŸã€‚")


if __name__ == "__main__":
    main() 